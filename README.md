# 阿里云Flink+DataHub数据同步问题排查总结
## 一、核心问题汇总（现象+根因）
| 序号 | 问题现象                                                                 | 根本原因                                                                 |
|------|--------------------------------------------------------------------------|--------------------------------------------------------------------------|
| 1    | DataHub Topic（ods_table_ri）数据被清空，Shard数据量为0                  | Topic生命周期配置为3天，数据到期后被系统自动清理；旧Topic不支持修改生命周期 |
| 2    | gmall_ods启动前造的数据无法同步到DataHub，Shard一直无数据                | Flink CDC（gmall_ods）基于binlog监听，启动前的数据无法被增量捕获          |
| 3    | DataHub新增数据op全为r，无预期的c（create）                              | gmall_ods处于全量同步阶段，新数据被当作全量数据同步，未进入增量监听阶段    |
| 4    | Flink SQL脚本调试失败（报Job restarted），且读不到DataHub数据            | Session集群不稳定（空闲超时/资源不足）；DataHub订阅位点未重置到最新        |
| 5    | Session集群频繁自动停止，需反复手动启动                                  | 集群空闲超时（无作业运行）；资源配置不足/账号配额不够；网络/权限不满足      |
| 6    | DataHub订阅位点找不到重置按钮，重置后仍读不到数据                        | 重置入口找错（详情页无按钮，需到订阅列表主页面）；集群不稳定导致脚本无法运行 |

## 二、对应解决方案（按问题闭环）
### 问题1：DataHub Topic数据被清空
1. 删除旧Topic（ods_table_ri）：因旧Topic不支持修改生命周期，直接删除；
2. 重建Topic：名称保持`ods_table_ri`，Shard数2，生命周期改为30天（避免快速清理）；
3. 重启gmall_ods：选择「无状态启动」，全量同步RDS数据到新Topic。

### 问题2：gmall_ods启动前造的数据无法同步
1. 正确流程：**先启动gmall_ods，再运行mock工具造数**（确保CDC监听开启后生成数据）；
2. 补同步历史数据：停止gmall_ods → 无状态启动 → 全量同步RDS中启动前的旧数据。

### 问题3：DataHub数据op全为r，无c
1. 等待全量同步完成：监控gmall_ods的`numRecordsInOfSourcePerSecond`指标回落至稳定值；
2. 增量造数：全量完成后，重新运行mock造数，新数据会被标记为op=c（增量同步）。

### 问题4：Flink SQL脚本调试失败+读不到数据
1. 稳定Session集群：
   - 停止旧集群，新建更高资源集群（4CPU+16GiB）；
   - 集群启动后立即启动gmall_ods，避免空闲超时；
2. 重置DataHub订阅位点：
   - 到DataHub订阅列表主页面（非详情页），找到对应subId → 重置位点到最新/1月1日后；
3. 脚本调试优化：
   - 调试前修改「更多配置」→ 并行度改为1（降低资源压力）→ 重新调试。

### 问题5：Session集群频繁自动停止
1. 避免空闲超时：启动集群后立即提交作业（如gmall_ods）；
2. 资源优化：调高集群CPU/内存，检查阿里云账号资源配额；
3. 网络/权限：确保集群、DataHub、RDS在同一VPC；给集群RAM角色添加`AliyunDataHubFullAccess`/`AliyunRDSFullAccess`权限。

### 问题6：DataHub订阅位点重置无效
1. 找对重置入口：回到订阅列表主页面，subId操作列点击「重置」；
2. 重置后验证：确保集群稳定运行，再调试脚本；若仍无数据，重新造数后重试。

## 三、核心知识点/实操技巧
### 1. Flink CDC同步机制
- 分两阶段：全量同步（op=r，读取RDS现有数据）→ 增量同步（op=c/u，监听binlog）；
- 全量完成前，新数据会被当作全量数据同步，op为r；仅增量阶段新数据op为c。

### 2. DataHub关键概念
- Shard：分布式存储分片，拆分数据提升读写并发/负载均衡；
- 生命周期：数据保存天数，到期自动清理，旧Topic需重建才能修改；
- 订阅位点：记录读数据的起始位置，跑偏会导致读不到新数据，需重置到最新。

### 3. Flink Session集群特性
- 任务依赖集群运行：集群停则任务停，仅集群运行时计费；
- 空闲超时策略：无作业运行时自动停止，需持续运行作业避免；
- 资源影响：并行度过高/资源不足会导致Job重启，调试时建议设并行度为1。

### 4. 故障排查核心逻辑
- 「读不到数据」≠「调试失败」：前者是业务数据问题，后者是集群/资源问题；
- 排查优先级：先解决集群稳定性（作业能跑），再解决数据读取（作业有结果）；
- 调试失败优先查集群资源/空闲超时，读不到数据优先查订阅位点/CDC同步阶段。

## 四、实操注意事项
1. 造数流程：必须先启动gmall_ods，再运行mock工具，否则数据无法被增量捕获；
2. 集群维护：启动后立即提交作业，避免空闲超时；定期检查生命周期，防止数据丢失；
3. 调试技巧：复杂脚本先降并行度，极简测试脚本（如datagen）验证集群是否稳定。

## 五、造数据实操步骤
### 1. 准备工作
- 本地安装JDK11版本（需匹配mock工具要求）；
- 在项目根目录的`tools`子目录下，放置业务数据模拟工具`mock-data-generator.jar`。

### 2. 操作步骤
1. **确认前置条件**：进入阿里云实时计算「作业运维」页面，确保`gmall_ods`任务处于「运行中」状态；
2. **执行造数命令**：
   打开终端/命令提示符，切换到项目根目录，执行mock工具命令：
   ```bash
   # Windows环境
   "C:\Program Files\Eclipse Adoptium\jdk-11.0.20.101-hotspot\bin\java.exe" -jar .\tools\mock-data-generator.jar
   
   # Linux/Mac环境
   java -jar ./tools/mock-data-generator.jar
   ```
3. **选择造数场景**：根据工具交互提示，选择生成订单表（`order_info`）、订单详情表（`order_detail`）等业务数据，设置造数数量（如10条/100条）。

### 3. 数据验证
1. **RDS验证**：登录RDS管理控制台，查看目标业务表（如`order_info`），确认新增模拟数据；
2. **DataHub验证**：进入DataHub的`ods_table_ri` Topic页面，点击「抽样」并选择最近时间范围，确认新数据（全量阶段op=r，增量阶段op=c）。
